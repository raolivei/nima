# Nima - Cursor Rules

## Workspace

See `../workspace-config/docs/PROJECT_CONVENTIONS.md` for shared conventions (git workflow, CHANGELOG, Docker/GHCR, K8s, security).

**Ports** (from `../workspace-config/ports/.env.ports`):

- Frontend: `3002`
- API: `8002`
- PostgreSQL: `5434`
- Redis: `6381`

## Commands

```bash
# Development (Docker Compose - recommended)
source ../workspace-config/ports/.env.ports
docker-compose up api              # Start API only
docker-compose up                  # Start all services

# Training (local - requires GPU/CPU)
python scripts/train.py --config configs/base_model.yaml        # Shakespeare
python scripts/train_technical.py --config configs/technical_training.yaml

# Monitoring
tensorboard --logdir experiments/logs   # Open http://localhost:6006

# Inference
python scripts/ask_nima.py --checkpoint experiments/nima_technical/checkpoint_best.pt --prompt "What is Kubernetes?"

# Linting (run after changes)
ruff check . && ruff format .
```

## Workflow

1. Always lint/format after code changes
2. Run tests before committing
3. Update CHANGELOG.md for all changes
4. Never run git commands at workspace root

## Project Overview

Educational AI/ML project - build language models from scratch with PyTorch. Beginner-friendly transformer implementation.

```
nima/
├── src/                    # Core AI model code
│   ├── models/            # Transformer architecture
│   ├── data/              # Text processing, tokenization
│   ├── training/          # Training loops, optimization
│   ├── inference/         # Text generation
│   └── memory/            # RAG memory system
├── scripts/               # User-facing scripts
├── configs/               # YAML training configs
├── experiments/           # Trained models (gitignored)
├── data/                  # Training datasets
├── api/                   # FastAPI inference API
└── k8s/                   # Kubernetes manifests
```

## Code Style

**Python**: See `src/models/transformer.py` for architecture patterns, `src/training/trainer.py` for training loop patterns.

**Educational focus**: Code should be readable and well-commented. Explain complex ML concepts.

## Common Tasks

### Training a Model

1. Prepare data in `data/raw/`
2. Create/update config in `configs/`
3. Run training script
4. Monitor with TensorBoard

### Adding New Dataset

1. Add raw data to `data/raw/`
2. Create processing script
3. Run: `python scripts/prepare_data.py`
4. Update config to point to processed data

## Docker Images

- API: `ghcr.io/raolivei/nima-api:<tag>`

## Key Concepts (Educational)

- **Transformer**: Attention mechanism, positional encoding, multi-head attention
- **Training**: Loss (cross-entropy), optimizer (Adam), learning rate scheduling
- **Evaluation**: Loss and perplexity (lower is better)

## Important Notes

- **Educational focus** - Readable, well-commented code
- **Small scale** - Learning, not production
- **Experiments** - Keep in `experiments/` (gitignored)
- **TensorBoard** - Monitor training progress
